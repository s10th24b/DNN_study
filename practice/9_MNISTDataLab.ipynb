{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import tensorflow as tf\n", "import numpy as np\n", "from tensorflow.examples.tutorials.mnist import input_data\n", "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nb_classes = 10 # 0~ 9\n", "X = tf.placeholder(tf.float32,[None,784]) # nb of pixels = 784\n", "Y = tf.placeholder(tf.float32,[None,nb_classes])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["W = tf.Variable(tf.random.normal([784,nb_classes])) # W\uc758 \ud06c\uae30\ub294 x\ud06c\uae30 * y\ud06c\uae30\uc774\ub2e4.\n", "b = tf.Variable(tf.random.normal([nb_classes])) #b\uc758 \ud06c\uae30\ub294 y\uc758 \ud06c\uae30\uc640 \uac19\ub2e4."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["logits = tf.matmul(X,W)+b\n", "hypothesis = tf.nn.softmax(logits)\n", "cost_i = -tf.reduce_sum(Y*tf.log(hypothesis),1)\n", "cost = tf.reduce_mean(cost_i)\n", "learning_rate = 0.1\n", "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["is_correct = tf.equal(tf.argmax(hypothesis,1),tf.argmax(Y,1))\n", "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["training_epochs = 15\n", "batch_size = 100"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["with tf.Session() as sess:\n", "    sess.run(tf.global_variables_initializer())\n", "    for epoch in range(training_epochs): #\uc804\uccb4 \ub370\uc774\ud130\uc14b\uc744 \ud55c\ubc88 \ub3c8\uac70 = 1 epoch\n", "        avg_cost = 0\n", "        total_batch = int(mnist.train.num_examples / batch_size) # 1 epoch\uc744 \uc5ec\ub7ec\uac1c\ub85c \ub098\ub208\uac8c 1 batch_size\n", "        # Iterations...\n", "        # \ub9cc\uc57d 1000\uac1c\uc758 \ud6c8\ub828 \uc14b\uc774 \uc788\uace0 \ubc30\uce58\uc0ac\uc774\uc988\uac00 500\uc774\uba74 2 iterations\n", "        # print(\"mnist.train.num_examples:\",mnist.train.num_examples)\n", "        # print(\"total_batch:\",total_batch)\n", "        for i in range(total_batch):\n", "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n", "            c,_ = sess.run([cost,optimizer],feed_dict={X:batch_xs,Y:batch_ys})\n", "            avg_cost+= c / total_batch\n", "        # print(\"Epoch:\",epoch+1,\"cost:\",avg_cost)\n", "        print(\"Epoch:\",\"%04d\"%(epoch+1),\"cost:\",\"{:.9f}\".format(avg_cost))\n", "        # print(\"hypothesis:\",sess.run(hypothesis,feed_dict={X:batch_xs,Y:batch_ys}))\n", "    print(\"Testing...\")\n", "    print(\"Accuracy:\",sess.run(accuracy,feed_dict={X:mnist.test.images,Y:mnist.test.labels}))\n", "    # print(\"Accuracy:\",accuracy.eval(session=sess,feed_dict={X:mnist.test.images,Y:mnist.test.labels}))\n", "    import matplotlib.pyplot as plt\n", "    import random\n\n", "    # get one and predict\n", "    r = random.randint(0,mnist.test.num_examples -1)\n", "    print(\"Label:\",sess.run(tf.argmax(mnist.test.labels[r:r+1],1)))\n", "    print(\"Prediction:\",sess.run(tf.argmax(hypothesis,1),feed_dict={X:mnist.test.images[r:r+1]}))\n", "    plt.imshow(mnist.test.images[r:r+1].reshape(28,28),cmap='Greys',interpolation='nearest')\n", "    plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}